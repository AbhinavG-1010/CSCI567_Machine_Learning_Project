{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (2.2.1)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: nltk in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (from nltk) (4.66.2)\n",
      "Requirement already satisfied: datasets in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (2.18.0)\n",
      "Requirement already satisfied: filelock in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (from datasets) (15.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (from datasets) (2.2.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (from datasets) (4.66.2)\n",
      "Requirement already satisfied: xxhash in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets) (2024.2.0)\n",
      "Requirement already satisfied: aiohttp in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (from datasets) (0.21.4)\n",
      "Requirement already satisfied: packaging in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (from datasets) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (from pandas->datasets) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: tqdm in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (4.66.2)\n",
      "Requirement already satisfied: ipywidgets in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (8.1.2)\n",
      "Requirement already satisfied: comm>=0.1.3 in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (from ipywidgets) (8.22.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (from ipywidgets) (5.14.2)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.10 in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (from ipywidgets) (4.0.10)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.10 in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (from ipywidgets) (3.0.10)\n",
      "Requirement already satisfied: decorator in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.42)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (2.17.2)\n",
      "Requirement already satisfied: stack-data in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Requirement already satisfied: Pillow in /Users/hrishikesh/miniconda3/envs/MLCS_project/lib/python3.11/site-packages (10.2.0)\n"
     ]
    }
   ],
   "source": [
    "# packages required for new environment\n",
    "! pip install pandas\n",
    "! pip install nltk\n",
    "! pip install datasets\n",
    "! pip install tqdm\n",
    "! pip install ipywidgets\n",
    "! pip install Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import datasets\n",
    "import nltk\n",
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. tiny-imagenet\n",
    "#   (a) Dataset Summary - Tiny ImageNet contains 100,000+ images of 200 classes (500 for each class) downsized to 64×64 colored images. Each class has 500 training images, 50 validation images, and 50 test images.\n",
    "#   (b) Data Feature Dimensions -\n",
    "#       i. Image: A PIL.Image.Image object containing the image.\n",
    "#       ii. Label: an int classification label. -1 for the test set as the labels are missing. Check classes.py for the map of numbers and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'tiny-imagenet-200' # Original images come in shapes of [3,64,64]\n",
    "# Define training and validation data paths\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, 'train') \n",
    "VALID_DIR = os.path.join(DATA_DIR, 'val')\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all class id and label from words.txt\n",
    "class_to_name_dict = dict()\n",
    "fp = open(os.path.join(DATA_DIR, 'words.txt'), 'r')\n",
    "data = fp.readlines()\n",
    "for line in data:\n",
    "    words = line.strip('\\n').split('\\t')\n",
    "    class_to_name_dict[words[0]] = words[1].split(',')[0]\n",
    "fp.close()\n",
    "\n",
    "# load images to dataframe\n",
    "def load_image(file_path):\n",
    "    try:\n",
    "        with Image.open(file_path) as img:\n",
    "            return img.convert('RGB')\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image from {file_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>H</th>\n",
       "      <th>W</th>\n",
       "      <th>Class</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=64x64 at ...</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>63</td>\n",
       "      <td>33</td>\n",
       "      <td>n04275548</td>\n",
       "      <td>spider web</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=64x64 at ...</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>63</td>\n",
       "      <td>n04532106</td>\n",
       "      <td>vestment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=64x64 at ...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>n02233338</td>\n",
       "      <td>cockroach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=64x64 at ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>40</td>\n",
       "      <td>n03400231</td>\n",
       "      <td>frying pan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=64x64 at ...</td>\n",
       "      <td>35</td>\n",
       "      <td>26</td>\n",
       "      <td>63</td>\n",
       "      <td>50</td>\n",
       "      <td>n02165456</td>\n",
       "      <td>ladybug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=64x64 at ...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>63</td>\n",
       "      <td>55</td>\n",
       "      <td>n02892201</td>\n",
       "      <td>brass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=64x64 at ...</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>63</td>\n",
       "      <td>n04562935</td>\n",
       "      <td>water tower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=64x64 at ...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>63</td>\n",
       "      <td>n03544143</td>\n",
       "      <td>hourglass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=64x64 at ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>n04067472</td>\n",
       "      <td>reel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=64x64 at ...</td>\n",
       "      <td>5</td>\n",
       "      <td>41</td>\n",
       "      <td>58</td>\n",
       "      <td>63</td>\n",
       "      <td>n02883205</td>\n",
       "      <td>bow tie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    File   X   Y   H   W  \\\n",
       "0      <PIL.Image.Image image mode=RGB size=64x64 at ...   0  25  63  33   \n",
       "1      <PIL.Image.Image image mode=RGB size=64x64 at ...  12   0  54  63   \n",
       "2      <PIL.Image.Image image mode=RGB size=64x64 at ...   0  10  63  63   \n",
       "3      <PIL.Image.Image image mode=RGB size=64x64 at ...   0   1  19  40   \n",
       "4      <PIL.Image.Image image mode=RGB size=64x64 at ...  35  26  63  50   \n",
       "...                                                  ...  ..  ..  ..  ..   \n",
       "99995  <PIL.Image.Image image mode=RGB size=64x64 at ...   0   3  63  55   \n",
       "99996  <PIL.Image.Image image mode=RGB size=64x64 at ...  28   1  56  63   \n",
       "99997  <PIL.Image.Image image mode=RGB size=64x64 at ...   3   3  33  63   \n",
       "99998  <PIL.Image.Image image mode=RGB size=64x64 at ...   0   1  63  63   \n",
       "99999  <PIL.Image.Image image mode=RGB size=64x64 at ...   5  41  58  63   \n",
       "\n",
       "           Class        label  \n",
       "0      n04275548   spider web  \n",
       "1      n04532106     vestment  \n",
       "2      n02233338    cockroach  \n",
       "3      n03400231   frying pan  \n",
       "4      n02165456      ladybug  \n",
       "...          ...          ...  \n",
       "99995  n02892201        brass  \n",
       "99996  n04562935  water tower  \n",
       "99997  n03544143    hourglass  \n",
       "99998  n04067472         reel  \n",
       "99999  n02883205      bow tie  \n",
       "\n",
       "[100000 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training datset creation \n",
    "tiny_imagenet_train = pd.DataFrame()\n",
    "for root, directories, files in os.walk(TRAIN_DIR):\n",
    "    for directory in directories:\n",
    "        d = pd.read_csv(os.path.join(root,directory, directory + \"_boxes.txt\"), \n",
    "                       sep='\\t', \n",
    "                       header=None, \n",
    "                       names=['File', 'X', 'Y', 'H', 'W'])\n",
    "        tiny_imagenet_train = pd.concat([tiny_imagenet_train,d])\n",
    "    break\n",
    "tiny_imagenet_train[\"Class\"]=tiny_imagenet_train.apply(lambda row: row.File.split('_')[0], axis=1)\n",
    "tiny_imagenet_train.File=tiny_imagenet_train.apply(lambda row: load_image(os.path.join(root, row.Class ,\"images\", row.File)), axis=1)\n",
    "tiny_imagenet_train['label']=tiny_imagenet_train.apply(lambda row: class_to_name_dict[row.Class], axis= 1)\n",
    "tiny_imagenet_train = tiny_imagenet_train.sample(frac=1).reset_index(drop=True)\n",
    "tiny_imagenet_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m10\u001b[39m))\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m25\u001b[39m):\n\u001b[1;32m      3\u001b[0m     plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m5\u001b[39m,i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(tiny_imagenet_train.iloc[i].File)\n",
    "    plt.xlabel(tiny_imagenet_train.iloc[i].label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation dataset creation \n",
    "\n",
    "# Display first 20 entries of resulting dictionary\n",
    "# {k: class_to_name_dict[k] for k in list(class_to_name_dict)[:20]}\n",
    "tiny_imagenet_valid = pd.read_csv(f'{VALID_DIR}/val_annotations.txt', \n",
    "                       sep='\\t', \n",
    "                       header=None, \n",
    "                       names=['File', 'Class', 'X', 'Y', 'H', 'W'])\n",
    "\n",
    "# tiny_imagenet_valid.head()\n",
    "# attaching label to respective class \n",
    "tiny_imagenet_valid[\"label\"] = tiny_imagenet_valid.apply(lambda row: class_to_name_dict[row.Class], axis= 1)\n",
    "tiny_imagenet_valid.File=tiny_imagenet_valid.apply(lambda row: load_image(os.path.join(VALID_DIR,\"images\", row.File)), axis=1)\n",
    "tiny_imagenet_valid = tiny_imagenet_valid.sample(frac=1).reset_index(drop=True)\n",
    "tiny_imagenet_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(tiny_imagenet_valid.iloc[i].File)\n",
    "    plt.xlabel(tiny_imagenet_valid.iloc[i].label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization Techniques for Dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. L2 Regularization - modifies the loss function. Applied to both datasets.\n",
    "# 2. Data Augmentation - modifies the data. For Dataset1 we plan to use RandomErasing\n",
    "#              - RandomErasing is concerned about removing and randomly adding information on the\n",
    "#               blank space, such as noise. For Dataset2 we plan to use Random Synonym Replacement -\n",
    "#               Random Synonym Replacement is concerned about removing and replacing with a synonym.\n",
    "# 3. MaxDropout - modifies training approach. Applied to both datasets.\n",
    "# 4. Ensemble Regularization 1 - applying RandomErasing and MaxDropout together. Applied to Dataset1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. nltk-brown + nltk-treebank + nltk-conll2000\n",
    "#   (a) Dataset Summary - The combination of these 3 datasets gives us a large corpus of\n",
    "#                       textual data that can be used for training a model that performs sequence labeling with\n",
    "#                       a total size of 72,000+ tagged sentences. The nltk library takes the base dataset and\n",
    "#                       performs tokenization to prepare it for the task of sequence labeling.\n",
    "#   (b) Data Feature Dimensions -\n",
    "#         i. Input Sequence - A sentence in english.\n",
    "#        ii. Output Sequence - POS tags of each word of the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "from nltk.corpus import treebank\n",
    "from nltk.corpus import conll2000\n",
    "nltk.download('brown')\n",
    "nltk.download('treebank')\n",
    "nltk.download('conll2000')\n",
    "nltk.download('universal_tagset')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treebank = treebank.tagged_sents(tagset='universal')\n",
    "brown = brown.tagged_sents(tagset='universal')\n",
    "conll2000 = conll2000.tagged_sents(tagset='universal')\n",
    "print(treebank[0])\n",
    "print(brown[0])\n",
    "print(conll2000[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(data):\n",
    "    sentences = []\n",
    "    pos_tags = []\n",
    "\n",
    "    for sequence in data:\n",
    "        sentence = []\n",
    "        tags = []\n",
    "        for seq in sequence:         \n",
    "            sentence.append(seq[0])\n",
    "            tags.append(seq[1])\n",
    "            \n",
    "        sentences.append(sentence)\n",
    "        pos_tags.append(tags)\n",
    "    return pd.DataFrame(zip(sentences, pos_tags), columns=[\"sentences\", \"pos_tags\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_dataset = create_dataset(treebank + brown + conll2000)\n",
    "corpus_dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization Techniques for Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. L2 Regularization - modifies the loss function. Applied to both datasets.\n",
    "# 2. Data Augmentation - modifies the data. For Dataset1 we plan to use RandomErasing\n",
    "#       - RandomErasing is concerned about removing and randomly adding information on the\n",
    "#         blank space, such as noise. For Dataset2 we plan to use Random Synonym Replacement -\n",
    "#         Random Synonym Replacement is concerned about removing and replacing with a synonym.\n",
    "# 3. MaxDropout - modifies training approach. Applied to both datasets.\n",
    "# 4. Ensemble Regularization 2 - applying RandomSynonymReplacement and MaxDropout together. Applied to Dataset2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLCS_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
